{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy\n",
    "import os\n",
    "import numpy as np\n",
    "from pysdf import SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIM = 256\n",
    "N_SAMPLES = 2000\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-5 * BATCH_SIZE\n",
    "DEV = torch.device(\"mps\")\n",
    "DELTA = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1000])\n"
     ]
    }
   ],
   "source": [
    "class DeepSDF(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, layer_size = 512, dropout_p = 0.2):\n",
    "        super(DeepSDF, self).__init__()\n",
    "        self.dropout_p = dropout_p\n",
    "        self.input_layer = self.create_layer_block(input_dim, layer_size)\n",
    "        self.layer2 = self.create_layer_block(layer_size, layer_size)\n",
    "        self.layer3 = self.create_layer_block(layer_size, layer_size)\n",
    "        self.layer4 = self.create_layer_block(layer_size, layer_size - input_dim)\n",
    "        self.layer5 = self.create_layer_block(layer_size, layer_size)\n",
    "        self.layer6 = self.create_layer_block(layer_size, layer_size)\n",
    "        self.layer7 = self.create_layer_block(layer_size, layer_size)\n",
    "        self.layer8 = self.create_layer_block(layer_size, 1)\n",
    "\n",
    "    def create_layer_block(self, input_size, output_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout_p)\n",
    "        )\n",
    "\n",
    "    def forward(self, latent_vec, coords):\n",
    "        \"\"\"\n",
    "        latent_vec has shape [batch_size, z_dim]\n",
    "        coords has shape [num_coords, 3]\n",
    "        \"\"\"\n",
    "        batch_size, num_coords = latent_vec.shape[0], coords.shape[0]\n",
    "        # latent_vec now has shape [batch_size, num_coords, z_dim], repeated on the middle axis\n",
    "        latent_vec = latent_vec.unsqueeze(1).repeat(1, num_coords, 1)\n",
    "        # coords now has shape [batch_size, num_coords, 3], repeated on this first axis\n",
    "        coords = coords.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "        x = torch.cat([latent_vec, coords], dim = -1)\n",
    "        skip_x = x\n",
    "\n",
    "        x = self.input_layer(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(torch.cat([x, skip_x], dim = -1)) # skip connection\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "\n",
    "        # return has shape [batch_size, num_coords], where each element is the SDF\n",
    "        # at the given input coordinate\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "test_model = DeepSDF(Z_DIM + 3)\n",
    "random_latent = torch.randn(32, Z_DIM)\n",
    "random_coords = torch.randn(1000, 3)\n",
    "output = test_model(random_latent, random_coords)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDFDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, num_samples, z_dim=256, latent_mean=0.0, latent_sd=0.01):\n",
    "        fnames = os.listdir(dataset_path)\n",
    "        if \".DS_Store\" in fnames:\n",
    "            fnames.remove(\".DS_Store\")\n",
    "        fnames = sorted(fnames)\n",
    "        self.file_paths = [os.path.join(dataset_path, i) for i in fnames]\n",
    "        self.num_samples = num_samples\n",
    "        self.latent_vectors = torch.randn(len(fnames), z_dim, requires_grad=True)\n",
    "        self.latent_vectors = (self.latent_vectors * latent_sd) + latent_mean\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pd_sampler = scipy.stats.qmc.PoissonDisk(d=3)\n",
    "        arr = np.load(self.file_paths[idx])\n",
    "        poisson_grid_points = pd_sampler.random(self.num_samples)\n",
    "        sdf_values = SDF(arr[\"vertices\"], arr[\"faces\"])(poisson_grid_points)\n",
    "        return torch.from_numpy(poisson_grid_points), self.latent_vectors[idx], torch.from_numpy(sdf_values)\n",
    "\n",
    "    def collate_fn(self, x):\n",
    "        min_sample_len = min([len(i[0]) for i in x])\n",
    "        x_vals = [i[0][:min_sample_len].unsqueeze(0) for i in x]\n",
    "        vec = [i[1].unsqueeze(0) for i in x]\n",
    "        y_vals = [i[2][:min_sample_len].unsqueeze(0) for i in x]\n",
    "        return torch.cat(x_vals, dim=0), torch.cat(vec, dim=0), torch.cat(y_vals, dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(266.0443, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeepSDFLoss:\n",
    "\n",
    "    def __init__(self, delta, sd):\n",
    "        self.mae = nn.L1Loss()\n",
    "        self.delta = delta\n",
    "        self.sd = sd\n",
    "\n",
    "    def __call__(self, yhat, y, latent):\n",
    "        l = self.mae(torch.clamp(yhat, -self.delta, self.delta), torch.clamp(y, -self.delta, self.delta))\n",
    "        latent_norm = torch.pow(latent, 2).sum(dim=-1).mean()  * (1 / (self.sd ** 2))\n",
    "        return l + latent_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SDFDataset(\n",
    "    dataset_path=\"/Users/gursi/Desktop/tight_models\",\n",
    "    num_samples=N_SAMPLES,\n",
    "    z_dim=Z_DIM\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSDF(Z_DIM + 3).to(DEV)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
